SmartShop 360 – Spécifications Techniques & Architecture Détaillée

Projet : Intégration E-commerce & Agent IA Métier
Domaine : E-commerce B2C (Décoration & Cadeaux)
Objectif : Unification des données transactionnelles et réputationnelles pour un pilotage 360°.

1. Contexte et Problématique Métier

1.1 La Situation Actuelle (Silos)

SmartShop 360 souffre d'une fragmentation de son système d'information :

Équipe Ventes & Finance : Utilise l'ERP (données structurées) pour piloter le CA et les marges.

Équipe Marketing & Qualité : Surveille les marketplaces (données non structurées) pour la réputation.

Conséquence : Aveuglement stratégique. Impossible de répondre à : "Quels sont nos best-sellers (Ventes) qui commencent à avoir une mauvaise réputation (Avis) ?"

1.2 La Solution Cible

Une architecture "Data + IA" permettant :

Unification : Création d'un entrepôt de données commun avec réconciliation des produits.

Visualisation : Dashboard unifié pour les KPIs croisés.

Interaction : Agent IA (Text-to-SQL) pour interroger les données en langage naturel.

2. Architecture des Données (ETL & MDM)

2.1 Sources de Données (Datasets Simulés)

Source

Type

Dataset Simulacre

Contenu Clé

ERP / Ventes

Structuré (CSV/SQL)

Online Retail II (Kaggle)

InvoiceNo, StockCode, Quantity, Price, CustomerID

Avis Clients

Non-structuré (JSON)

Ecommerce Product Reviews

ReviewText, Rating (1-5), Sentiment

2.2 Stratégie ETL (Extract, Transform, Load)

Le pipeline Python (etl.py) doit effectuer les opérations suivantes :

Ingestion & Nettoyage (Source Ventes) :

Filtrage des commandes annulées (InvoiceNo commençant par 'C').

Conversion des formats de dates (InvoiceDate).

Gestion des valeurs nulles (ex: CustomerID).

Ingestion (Source Avis) :

Chargement d'un échantillon significatif (500-1000 avis).

Normalisation des scores de sentiment si nécessaire.

Master Data Management (MDM) - Le Défi du Mapping :

Problème : Les IDs produits ne correspondent pas entre l'ERP et le site d'avis.

Solution (Artificielle pour le POC) : Création d'une Table de Mapping (Golden Record).

Algorithme : Associer le Top 50 des produits vendus (Source 1) aux 50 produits les plus commentés (Source 2).

Résultat : Une table de jointure PRODUCT_MAPPING permettant les requêtes SQL croisées.

2.3 Modélisation de l'Entrepôt (PostgreSQL)

-- Table Pivot (MDM)
CREATE TABLE Product_Mapping (
    MappingID SERIAL PRIMARY KEY,
    ERP_StockCode VARCHAR(50), -- Clé étrangère vers Ventes
    Review_ProductID VARCHAR(50), -- Clé étrangère vers Avis
    Unified_Name VARCHAR(255) -- Nom officiel "Golden"
);

-- Table de Faits : Ventes
CREATE TABLE Sales_Facts (
    FactID SERIAL PRIMARY KEY,
    InvoiceNo VARCHAR(20),
    StockCode VARCHAR(50), -- Lien vers ERP_StockCode
    Quantity INT,
    Revenue DECIMAL(10,2), -- Quantity * UnitPrice
    InvoiceDate TIMESTAMP
);

-- Table de Faits : Avis
CREATE TABLE Review_Facts (
    ReviewID SERIAL PRIMARY KEY,
    ProductID VARCHAR(50), -- Lien vers Review_ProductID
    Rating INT, -- 1 à 5
    ReviewText TEXT,
    SentimentLabel VARCHAR(20) -- POSITIVE/NEGATIVE
);


3. Mini-Orchestrateur IA (Agent SQL)

L'agent agit comme un "Data Analyst Virtuel". Il ne doit pas halluciner les chiffres mais interroger la base réelle.

3.1 Architecture "Chat with your Data"

LLM : Utilisation d'une API performante en génération de code (Groq/Llama 3, OpenAI/GPT-4o, Mistral).

Rôle : Traducteur "Langage Naturel vers SQL".

3.2 Les Outils (Tools) de l'Agent

Tool_SQL_Executor (Obligatoire) :

Input : Une question utilisateur.

Process : Le LLM reçoit le schéma de la BDD (DDL) -> Génère le SQL -> Exécute sur Postgres.

Sécurité : Accès en lecture seule (READ ONLY user).

Exemple Prompt Système : "Tu es un expert SQL. Utilise la table Product_Mapping pour joindre Sales_Facts et Review_Facts."

Tool_Data_Analysis (Optionnel) :

Script Python (Pandas) pour des calculs que SQL gère mal (ex: corrélation linéaire complexe, tendances temporelles fines).

3.3 Scénario d'Exécution

User : "Quels produits vendus à plus de 100 unités ont une note < 3/5 ?"

Agent (Pensée) : "Je dois joindre les ventes et les avis via la table de mapping, filtrer sur SUM(Quantity) > 100 et AVG(Rating) < 3."

Agent (Action) : Exécute :

SELECT m.Unified_Name, SUM(s.Quantity), AVG(r.Rating)
FROM Product_Mapping m
JOIN Sales_Facts s ON m.ERP_StockCode = s.StockCode
JOIN Review_Facts r ON m.Review_ProductID = r.ProductID
GROUP BY m.Unified_Name
HAVING SUM(s.Quantity) > 100 AND AVG(r.Rating) < 3;


Agent (Réponse) : "J'ai trouvé 3 produits correspondant à vos critères, dont le 'Mug Bleu'..."

4. Interface Utilisateur (UI)

Framework recommandé pour le RAD (Rapid Application Development) : Streamlit.

4.1 Écrans Attendus

Dashboard "Data Quality" :

Indicateur de couverture : "50 produits unifiés sur 3000".

KPIs globaux : CA Total, Note Moyenne Globale.

Interface "Chat" :

Zone de chat type messagerie.

Affichage optionnel du code SQL généré (pour la transparence/débogage).

Fiche Produit 360° :

Sélection d'un produit dans une liste déroulante.

Graphique 1 : Courbe des ventes sur 6 mois.

Graphique 2 : Histogramme des notes (1-5 étoiles).

Liste des 3 derniers avis textuels.

5. Livrables du Projet

5.1 Livrables Urbaniste (Architecture)

Vue Métier (ArchiMate) : Processus Vente vs Processus Qualité.

Diagramme de Flux (DFD) : Source -> Nettoyage -> Mapping -> Warehouse.

Architecture Physique : Docker (App, DB) + API LLM.

5.2 Proof of Concept (Code)

Repo Git contenant :

etl.py : Script d'ingestion et de mapping artificiel.

app.py : Application Streamlit.

agent.py : Logique LangChain/LLM.

docker-compose.yml : Pour lancer la BDD et l'app.

README.md : Instructions de démarrage rapide.

5.3 Démonstration

Vidéo (5-10 min) :

Lancement du script ETL (montrer les logs).

Exploration du Dashboard.

Question complexe à l'Agent (ex: segments rentables et satisfaits).


6. Guide d'Implémentation & Stack Technique

Pour réussir le POC rapidement (Rapid Application Development), voici la stack précise à utiliser.

6.1 Fichier requirements.txt

# Data Engineering & Database
pandas==2.2.0
sqlalchemy==2.0.0
psycopg2-binary==2.9.9  # Driver PostgreSQL
python-dotenv==1.0.0    # Gestion des variables d'environnement

# AI & LLM
langchain==0.1.0
langchain-community==0.0.10
langchain-openai==0.0.5 # Ou langchain-groq / langchain-mistral
openai==1.10.0

# UI & Dashboard
streamlit==1.30.0
plotly==5.18.0          # Pour des graphiques interactifs (mieux que matplotlib)


6.2 Variables d'Environnement (.env)

Ne jamais coder les clés en dur. Créez un fichier .env :

POSTGRES_USER=admin
POSTGRES_PASSWORD=password
POSTGRES_DB=smartshop_db
POSTGRES_HOST=localhost
OPENAI_API_KEY=sk-proj-... (ou GROQ_API_KEY)


7. Stratégie MDM : Du POC à la Réalité (Point Critique)

Ce chapitre répond à l'exigence du PDF : "Décrivez comment vous auriez procédé dans un contexte réel".

7.1 Approche POC (Actuelle)

Méthode : Mapping basé sur le Rang (Rank-based matching).

Logique : On suppose arbitrairement que le produit le plus vendu (ERP) est le produit le plus commenté (Web).

Limite : Aucune fiabilité sémantique. C'est une astuce technique pour permettre la jointure SQL lors de la démo.

7.2 Approche "Monde Réel" (Production)

Dans un vrai projet d'urbanisation SI, voici les méthodes étagées par fiabilité :

Codes Universels (Hard Match) - Priorité 1 :

Utilisation des codes EAN-13 (Code-barres), GTIN ou UPC.

Si l'ERP et la Marketplace fournissent ce champ, la réconciliation est déterministe et fiable à 100%.

Fuzzy Matching (Soft Match) - Priorité 2 :

Si pas de code EAN commun, on compare les noms de produits (Description vs Product Name).

Technique : Distance de Levenshtein (librairie thefuzz en Python).

Seuil : Si similarité > 90%, on crée le lien automatiquement. Si entre 70% et 90%, on flag pour validation humaine.

Semantic Matching (IA) - Priorité 3 :

Pour les descriptions très différentes (ex: "Mug Bleu" vs "Tasse Céramique Azur").

Technique : Utilisation d'Embeddings (Vectorisation). On transforme les titres en vecteurs (ex: via Sentence-BERT) et on calcule la similarité cosinus.

8. Structure du Projet (Repository Git)

Une structure propre est essentielle pour la maintenabilité et la notation.

SmartShop360/
│
├── data/                       # Données brutes (ignorées par git si volumineuses)
│   ├── online_retail_II.csv    # Source Kaggle
│   └── reviews.json            # Source Hugging Face
│
├── src/
│   ├── __init__.py
│   ├── db_config.py            # Connexion SQLAlchemy
│   │
│   ├── etl/                    # Pipeline de données
│   │   ├── cleaning.py         # Fonctions de nettoyage
│   │   ├── mdm_mapping.py      # Logique de création de la table pivot
│   │   └── run_etl.py          # Script principal d'ingestion
│   │
│   ├── agent/                  # Cerveau IA
│   │   ├── tools.py            # Définition des Tools (SQL, Python)
│   │   └── graph.py            # Chaîne LangChain / Prompt Templates
│   │
│   └── ui/                     # Interface Streamlit
│       ├── dashboard.py        # Composants graphiques
│       └── chat.py             # Interface de chat
│
├── app.py                      # Point d'entrée principal (Streamlit run)
├── docker-compose.yml          # Conteneur PostgreSQL
├── requirements.txt            # Dépendances
└── README.md                   # Guide d'installation


9. Plan de Développement (Roadmap)

Phase 1 : Fondations Data (Jours 1-2)

Lancer le conteneur PostgreSQL via Docker.

Écrire le script run_etl.py pour lire les CSV.

Implémenter la logique "Top 50 Mapping".

Vérifier dans DBeaver ou PgAdmin que les tables Sales_Facts, Review_Facts et Product_Mapping sont remplies et jointables.

Phase 2 : Intelligence Artificielle (Jours 3-4)

Configurer LangChain avec l'accès à la BDD.

Tester le Tool_SQL_Executor isolément avec un script simple.

Test : "Donne-moi le CA total".

Affiner le "System Prompt" pour qu'il comprenne bien le schéma de mapping (lui dire explicitement : "Passe toujours par la table Product_Mapping pour joindre ventes et avis").

Phase 3 : Interface & Intégration (Jours 4-5)

Monter l'app Streamlit basique.

Connecter le Chatbot à l'agent créé en Phase 2.

Ajouter les graphiques Plotly pour la vue 360°.

Enregistrer la vidéo de démo.

10. Gestion des Risques & Conseils

Hallucinations SQL :

Risque : L'IA invente des noms de colonnes.

Parade : Dans le prompt de l'agent, injectez le DDL (Data Definition Language - les CREATE TABLE) exact.

Performance ETL :

Risque : Le chargement prend trop de temps.

Parade : Ne chargez pas tout le dataset Kaggle. Prenez les 6 derniers mois ou un échantillon de 10 000 lignes pour le POC.

Problème de Mapping :

Risque : La jointure renvoie vide.

Parade : Assurez-vous que les IDs dans Product_Mapping existent bien exactement dans les tables sources (attention aux espaces invisibles ou à la casse).