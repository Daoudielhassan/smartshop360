"""
SmartShop 360 - Agent IA (Mini-Orchestrateur)
===============================================
Architecture :
- L'agent re√ßoit une question en langage naturel
- Il g√©n√®re une requ√™te SQL gr√¢ce au LLM (multi-provider)
- Il ex√©cute la requ√™te sur la base SQLite
- Il formule une r√©ponse en langage naturel

Pattern : Text-to-SQL (RAG structur√©)

Providers LLM support√©s (par ordre de priorit√©) :
  1. Groq     ‚Äî GROQ_API_KEY      (llama-3.3-70b-versatile)
  2. Mistral  ‚Äî MISTRAL_API_KEY   (mistral-large-latest)
  3. OpenAI   ‚Äî OPENAI_API_KEY    (gpt-4o-mini)
  4. Anthropic‚Äî ANTHROPIC_API_KEY (claude-sonnet-4-20250514)
  5. Fallback ‚Äî r√®gles SQL int√©gr√©es (sans API)
"""

import sqlite3
import os
import json
import re
import requests

DB_PATH = os.path.join(os.path.dirname(__file__), "data", "smartshop360.db")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# SCH√âMA DE LA BASE (inject√© dans le prompt)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DB_SCHEMA = """
Base de donn√©es SQLite - SmartShop 360

TABLES PRINCIPALES :
--------------------
CUSTOMERS(ClientID, Nom, Pays)
PRODUCTS(ProductID, ProductName, Category)
INVOICES(FactureID, ClientID, Date, MontantTotal)
INVOICE_LINES(LigneID, FactureID, ProduitID, Quantite, PrixUnitaire, Revenue, Margin)
REVIEWS(ReviewID, ReviewText, Sentiment, Note, ReviewDate, ProduitID)
PRODUCT_MAPPING(MappingID, ERP_ProductCode, ERP_ProductName, Review_ProductCode, Review_ProductName, Category, GoldenRecordName)

VUES ANALYTIQUES (pr√©f√©rer pour les KPIs) :
--------------------------------------------
V_PRODUCT_KPI(ProductID, ProductName, Category, CA, Marge, QuantiteVendue, Notemoyenne, NbAvis, AvisPositifs, AvisNegatifs, AvisNeutres)
V_CUSTOMER_KPI(ClientID, Nom, Pays, NbCommandes, CA_Total, PanierMoyen)
V_ALERTS(ProductID, ProductName, Category, CA, Notemoyenne, NbAvis, AvisNegatifs, QuantiteVendue, Statut)
  ‚Üí Statut peut √™tre : 'CRITIQUE', 'A_SURVEILLER', 'OK'
V_DATA_QUALITY(Nb_Produits_ERP, Nb_Produits_Avis, Nb_Mappings, Nb_Avis_Total, Nb_Avis_Lies, Nb_Factures, Nb_Clients, Taux_Couverture_MDM)

NOTES :
- Sentiment dans REVIEWS : 'positive', 'negative', 'neutral'
- Note dans REVIEWS : de 1.0 √† 5.0
- CA = Chiffre d'Affaires (Revenue total)
- Utiliser SQLite (pas de ILIKE, utiliser LIKE en majuscules ou LOWER())
- Les donn√©es transactions viennent du CSV r√©el Online Retail II (Kaggle)
"""

SYSTEM_PROMPT = f"""Tu es un Data Analyst expert pour SmartShop 360, un e-commer√ßant B2C sp√©cialis√© en D√©coration & Cadeaux.

Tu as acc√®s √† une base de donn√©es SQLite avec le sch√©ma suivant :
{DB_SCHEMA}

Ta mission est de :
1. Comprendre la question m√©tier de l'utilisateur
2. G√©n√©rer une requ√™te SQL valide et optimis√©e
3. Analyser les r√©sultats et formuler une r√©ponse claire en fran√ßais

Format de r√©ponse OBLIGATOIRE (JSON strict) :
{{
  "sql": "SELECT ...",
  "reasoning": "Explication courte de l'approche",
  "answer_template": "Template de r√©ponse √† compl√©ter avec les donn√©es"
}}

R√®gles SQL :
- Utilise uniquement du SQL compatible SQLite
- Pr√©f√®re les vues analytiques (V_PRODUCT_KPI, V_CUSTOMER_KPI, V_ALERTS) aux tables brutes
- Limite les r√©sultats √† 20 lignes max avec LIMIT
- Arrondis les montants avec ROUND(x, 2)
- Ne g√©n√®re qu'une seule requ√™te SQL
"""

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# TOOL 1 : SQL EXECUTOR
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def execute_sql(query: str) -> dict:
    """Ex√©cute une requ√™te SQL et retourne les r√©sultats."""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute(query)
        rows = cur.fetchall()
        columns = [desc[0] for desc in cur.description] if cur.description else []
        data = [dict(zip(columns, row)) for row in rows]
        conn.close()
        return {"success": True, "data": data, "columns": columns, "row_count": len(data)}
    except Exception as e:
        return {"success": False, "error": str(e), "data": [], "columns": []}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# TOOL 2 : PYTHON ANALYTIQUE (calculs avanc√©s)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def python_analysis(data: list, analysis_type: str = "summary") -> dict:
    """Calculs statistiques compl√©mentaires sur les donn√©es."""
    if not data:
        return {"result": "Aucune donn√©e √† analyser"}
    
    import statistics
    
    if analysis_type == "summary":
        numeric_cols = {}
        for row in data:
            for k, v in row.items():
                if isinstance(v, (int, float)):
                    numeric_cols.setdefault(k, []).append(v)
        
        summary = {}
        for col, values in numeric_cols.items():
            summary[col] = {
                "min": round(min(values), 2),
                "max": round(max(values), 2),
                "moyenne": round(statistics.mean(values), 2),
                "mediane": round(statistics.median(values), 2),
            }
        return {"result": summary}
    
    return {"result": "Analyse non reconnue"}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# AGENT PRINCIPAL
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _detect_provider(api_key: str | None = None) -> tuple[str, str]:
    """
    D√©tecte automatiquement le provider LLM disponible.
    Priorit√© : Groq > Mistral > OpenAI > Anthropic > Fallback
    Retourne (provider_name, api_key)
    """
    # Cl√© explicitement pass√©e ‚Üí d√©tecter son type par pr√©fixe (priorit√© sur longueur)
    if api_key:
        if api_key.startswith("gsk_"):      return ("groq", api_key)
        if api_key.startswith("sk-ant-"):   return ("anthropic", api_key)
        if api_key.startswith("sk-"):       return ("openai", api_key)
        # Mistral : cl√© sans pr√©fixe standard, entre 32 et 64 chars hexad√©cimaux
        if 28 <= len(api_key) <= 64 and not api_key.startswith("sk"):
            return ("mistral", api_key)

    # Variables d'environnement
    if os.environ.get("GROQ_API_KEY"):
        return ("groq", os.environ["GROQ_API_KEY"])
    if os.environ.get("MISTRAL_API_KEY"):
        return ("mistral", os.environ["MISTRAL_API_KEY"])
    if os.environ.get("OPENAI_API_KEY"):
        return ("openai", os.environ["OPENAI_API_KEY"])
    if os.environ.get("ANTHROPIC_API_KEY"):
        return ("anthropic", os.environ["ANTHROPIC_API_KEY"])

    return ("fallback", "")


def _call_groq(messages: list, system: str, key: str, max_tokens: int = 1024) -> str:
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {
        "model": "llama-3.3-70b-versatile",
        "max_tokens": max_tokens,
        "messages": [{"role": "system", "content": system}] + messages,
    }
    r = requests.post("https://api.groq.com/openai/v1/chat/completions",
                      headers=headers, json=payload, timeout=30)
    if r.status_code == 200:
        return r.json()["choices"][0]["message"]["content"]
    raise RuntimeError(f"Groq error {r.status_code}: {r.text[:200]}")


def _call_mistral(messages: list, system: str, key: str, max_tokens: int = 1024) -> str:
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {
        "model": "mistral-large-latest",
        "max_tokens": max_tokens,
        "messages": [{"role": "system", "content": system}] + messages,
    }
    r = requests.post("https://api.mistral.ai/v1/chat/completions",
                      headers=headers, json=payload, timeout=30)
    if r.status_code == 200:
        return r.json()["choices"][0]["message"]["content"]
    raise RuntimeError(f"Mistral error {r.status_code}: {r.text[:200]}")


def _call_openai(messages: list, system: str, key: str, max_tokens: int = 1024) -> str:
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {
        "model": "gpt-4o-mini",
        "max_tokens": max_tokens,
        "messages": [{"role": "system", "content": system}] + messages,
    }
    r = requests.post("https://api.openai.com/v1/chat/completions",
                      headers=headers, json=payload, timeout=30)
    if r.status_code == 200:
        return r.json()["choices"][0]["message"]["content"]
    raise RuntimeError(f"OpenAI error {r.status_code}: {r.text[:200]}")


def _call_anthropic(messages: list, system: str, key: str, max_tokens: int = 1024) -> str:
    headers = {
        "Content-Type": "application/json",
        "x-api-key": key,
        "anthropic-version": "2023-06-01",
    }
    payload = {
        "model": "claude-sonnet-4-20250514",
        "max_tokens": max_tokens,
        "system": system,
        "messages": messages,
    }
    r = requests.post("https://api.anthropic.com/v1/messages",
                      headers=headers, json=payload, timeout=30)
    if r.status_code == 200:
        return r.json()["content"][0]["text"]
    raise RuntimeError(f"Anthropic error {r.status_code}: {r.text[:200]}")


def call_llm(messages: list, api_key: str| None = None, max_tokens: int = 1024) -> str:
    """
    Appelle le meilleur LLM disponible.
    D√©tection automatique du provider via les cl√©s API (env ou param√®tre).
    """
    provider, key = _detect_provider(api_key)

    try:
        if provider == "groq":
            return _call_groq(messages, SYSTEM_PROMPT, key, max_tokens)
        elif provider == "mistral":
            return _call_mistral(messages, SYSTEM_PROMPT, key, max_tokens)
        elif provider == "openai":
            return _call_openai(messages, SYSTEM_PROMPT, key, max_tokens)
        elif provider == "anthropic":
            return _call_anthropic(messages, SYSTEM_PROMPT, key, max_tokens)
    except Exception as e:
        print(f"‚ö†Ô∏è [{provider}] Erreur API : {e} ‚Äî basculement sur le fallback SQL")

    # Fallback sans LLM
    return generate_sql_fallback(messages[-1]["content"])


def get_active_provider(api_key: str| None = None) -> str:
    """Retourne le nom du provider actif (pour affichage dans l'UI)."""
    provider, key = _detect_provider(api_key)
    labels = {
        "groq":      "üü¢ Groq (Llama 3.3-70B)",
        "mistral":   "üü† Mistral (Large)",
        "openai":    "üîµ OpenAI (GPT-4o-mini)",
        "anthropic": "üü£ Anthropic (Claude Sonnet 4)",
        "fallback":  "‚ö´ Mode hors-ligne (r√®gles SQL)",
    }
    return labels.get(provider, provider)

def generate_sql_fallback(question: str) -> str:
    """G√©n√©ration SQL bas√©e sur des r√®gles simples (sans API LLM)."""
    q = question.lower()
    
    if any(w in q for w in ["alerte", "surveiller", "critique", "mauvais avis"]):
        sql = "SELECT ProductName, CA, Notemoyenne, AvisNegatifs, Statut FROM V_ALERTS WHERE Statut != 'OK' ORDER BY Notemoyenne ASC LIMIT 10"
        reasoning = "Recherche des produits avec des alertes qualit√©"
    elif any(w in q for w in ["top", "meilleur", "best", "vente", "ca"]):
        sql = "SELECT ProductName, Category, CA, QuantiteVendue, Notemoyenne FROM V_PRODUCT_KPI ORDER BY CA DESC LIMIT 10"
        reasoning = "Classement des produits par chiffre d'affaires"
    elif any(w in q for w in ["client", "segment", "fid√®le", "rentable"]):
        sql = "SELECT Nom, Pays, NbCommandes, CA_Total, PanierMoyen FROM V_CUSTOMER_KPI ORDER BY CA_Total DESC LIMIT 10"
        reasoning = "Analyse des meilleurs clients"
    elif any(w in q for w in ["cat√©gorie", "categorie"]):
        sql = "SELECT Category, ROUND(SUM(CA),2) as CA_Total, ROUND(AVG(Notemoyenne),2) as Note_Moy, SUM(QuantiteVendue) as Qte FROM V_PRODUCT_KPI GROUP BY Category ORDER BY CA_Total DESC"
        reasoning = "Performance par cat√©gorie"
    elif any(w in q for w in ["sentiment", "avis", "satisfaction"]):
        sql = "SELECT ProductName, Notemoyenne, NbAvis, AvisPositifs, AvisNegatifs FROM V_PRODUCT_KPI WHERE NbAvis > 5 ORDER BY Notemoyenne DESC LIMIT 15"
        reasoning = "Analyse du sentiment client par produit"
    elif any(w in q for w in ["pays", "country", "g√©ographie"]):
        sql = "SELECT Pays, COUNT(*) as NbClients, ROUND(SUM(CA_Total),2) as CA FROM V_CUSTOMER_KPI GROUP BY Pays ORDER BY CA DESC"
        reasoning = "Analyse g√©ographique"
    else:
        sql = "SELECT ProductName, CA, Marge, QuantiteVendue, Notemoyenne FROM V_PRODUCT_KPI ORDER BY CA DESC LIMIT 10"
        reasoning = "Vue g√©n√©rale des KPIs produits"
    
    return json.dumps({
        "sql": sql,
        "reasoning": reasoning,
        "answer_template": "Voici les r√©sultats de votre analyse."
    })

def parse_agent_response(response_text: str) -> dict:
    """Parse la r√©ponse JSON de l'agent."""
    # Cherche le JSON dans la r√©ponse
    json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group())
        except json.JSONDecodeError:
            pass
    
    # Fallback
    return {
        "sql": "SELECT ProductName, CA, Notemoyenne FROM V_PRODUCT_KPI ORDER BY CA DESC LIMIT 10",
        "reasoning": "Requ√™te par d√©faut",
        "answer_template": "Voici les donn√©es disponibles."
    }

def format_natural_response(question: str, sql: str, data: list, reasoning: str, api_key: str | None = None) -> str:
    """G√©n√®re la r√©ponse finale en langage naturel."""
    if not data:
        return "Aucune donn√©e ne correspond √† votre question."

    data_str = json.dumps(data[:10], ensure_ascii=False, indent=2)
    provider, key = _detect_provider(api_key)

    if key and provider != "fallback":
        user_msg = f"""Question de l'utilisateur : {question}

R√©sultats SQL (top 10) :
{data_str}

G√©n√®re une r√©ponse claire et utile en fran√ßais pour un responsable marketing ou qualit√©.
Sois concis (3-5 phrases max), mets en avant les insights cl√©s et recommande des actions si pertinent."""
        system_msg = "Tu es un analyste data senior pour SmartShop 360. Tes r√©ponses sont concises, orient√©es action et en fran√ßais."
        messages = [{"role": "user", "content": user_msg}]

        try:
            if provider == "groq":
                return _call_groq(messages, system_msg, key, max_tokens=512)
            elif provider == "mistral":
                return _call_mistral(messages, system_msg, key, max_tokens=512)
            elif provider == "openai":
                return _call_openai(messages, system_msg, key, max_tokens=512)
            elif provider == "anthropic":
                return _call_anthropic(messages, system_msg, key, max_tokens=512)
        except Exception:
            pass

    # Fallback : r√©ponse structur√©e simple
    lines = [f"üìä **Analyse : {question}**\n"]
    lines.append(f"*Approche : {reasoning}*\n")
    lines.append(f"**{len(data)} r√©sultat(s) trouv√©(s) :**\n")
    for i, row in enumerate(data[:5], 1):
        parts = [f"{k}: **{v}**" for k, v in row.items()]
        lines.append(f"{i}. {' | '.join(parts)}")
    if len(data) > 5:
        lines.append(f"\n*...et {len(data)-5} autres r√©sultats.*")
    return "\n".join(lines)

def run_agent(question: str, api_key: str | None = None, conversation_history: list | None = None) -> dict:
    """
    Boucle d'orchestration principale.
    
    Retourne :
    {
        "question": str,
        "sql": str,
        "reasoning": str,
        "data": list,
        "answer": str,
        "row_count": int
    }
    """
    if conversation_history is None:
        conversation_history = []
    
    # √âtape 1 : L'agent g√©n√®re le SQL
    messages = conversation_history + [{"role": "user", "content": question}]
    llm_response = call_llm(messages, api_key)
    parsed = parse_agent_response(llm_response)
    
    sql_query = parsed.get("sql", "")
    reasoning = parsed.get("reasoning", "")
    
    # √âtape 2 : Ex√©cution SQL (Tool)
    sql_result = execute_sql(sql_query)
    
    # √âtape 3 : R√©ponse en langage naturel
    if sql_result["success"]:
        answer = format_natural_response(question, sql_query, sql_result["data"], reasoning, api_key)
    else:
        answer = f"‚ùå Erreur lors de l'ex√©cution de la requ√™te : {sql_result.get('error', 'Erreur inconnue')}"
    
    return {
        "question": question,
        "sql": sql_query,
        "reasoning": reasoning,
        "data": sql_result.get("data", []),
        "columns": sql_result.get("columns", []),
        "answer": answer,
        "row_count": sql_result.get("row_count", 0),
        "success": sql_result["success"]
    }

if __name__ == "__main__":
    print("ü§ñ Test de l'agent SmartShop 360\n")
    questions = [
        "Quels produits vendus √† plus de 50 unit√©s ont une note inf√©rieure √† 3 ?",
        "Quels sont nos 5 meilleurs produits en chiffre d'affaires ?",
        "Quels segments de clients sont les plus rentables ?",
    ]
    for q in questions:
        print(f"\n‚ùì {q}")
        result = run_agent(q)
        print(f"üîç SQL: {result['sql']}")
        print(f"üí° {result['answer'][:300]}")
        print("-" * 60)
